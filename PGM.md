- Overview and Motivation
  - some of the usage: image segmentation, predisposing factors of symptoms, textual information extraction, multi-sensor integration (such as traffic)
  - what is model: The model is a declarative representation of our understanding of the world. So it is a representation within the computer that captures our understanding of what these variables are and how they interact with each other.
  - probabilistic -> uncertainty
  - think of the world as a bunch of random variables and each capture some facet of the world. Goal is to capture the uncertainty of the world in terms of the probability distribution (joint distribution)
  - Graphical models such as Bayesian networks (directed graph), Markov networks (undirected graph)
  - Distribution:
    - Joint probability, independent (if there are 12 cases then 11 of them are independent because they sum to 1)
    - Conditioning: Reduction and renormalization
    - Marginalization: sum over one RV of a joint probability: <a href="https://www.codecogs.com/eqnedit.php?latex=\sum&space;_{I}P(I,D)&space;=&space;P(D)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\sum&space;_{I}P(I,D)&space;=&space;P(D)" title="\sum _{I}P(I,D) = P(D)" /></a>
  - Factor:
    - fundamental building block for defining distributions in high-dimentional spaces
    - set of basic operations for manipulating these probability distributions
    - A factor really is a function, or a table. It takes a bunch of arguments. In this case, a set of random variables X1 up to XK, and just like any function it gives us a value for every assignment to those random variables.
    - the scope of a factor is the RV it can take
    - one factor we will use is conditional probability distribution (CPD) such as P(G|I,D)
    - factor product: it is like join two tables and multiply the corresponding factor value
    - factor marginalization: sum over one RV and reduce the table
    - factor reduction: eliminate a specific value of a RV or eliminate a RV (the difference betwee this and above is that one is elimination, the other is sum)
- Semantics & Factorization
  - Construct Bayesian network for a student example, conditional probability distribution is used in a node that is linked by other nodes. For instance, we have P(D), P(I), P(G|I,D), P(S|I), P(L|G)
