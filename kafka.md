- Architecture that cause problem
  - if you have 4 source systems and 6 target systems, you need to write 24 integrations
  - Each integration comes with difficulties around
    - protocol - how data is transported (TCP, HTTP etc)
    - Data format - how data is parsed (binary, CSV, JSON etc)
    - Data schema & evolution - how the data is shaped and may change
  - each source system will have an increasesd load from the connections
  - Apache Kafka comes in: source systems -> kafka -> target systems
    - Kafka is a high-throughput distributed messaging system
    - can scale to 100s of brokers, can scale to millions of messages per second
    - high performance (latency of less than 10ms) - real time
    - usage cases:
      - messaging system
      - activity tracking
      - gather metrics from many different locations
      - application logs gathering
      - stream processing
      - De-coupling of system dependencies
      - Integration with Spark, Flink, Storm, Hadoop and many other big data technologies
- Kafka theory
  - Topics: a particular stream of data
    - similar to a table in database (without all the constraints)
    - you can have as many topics as you want
    - A topic is identified by its name
  - partitions: topics are split in partitions
    - each partition is ordered (order is guaranteed only within a partition not across partitions)
    - each message within a partition gets an incremental id called **offset** (each partition has its own offset)
    - Data is kept only for a limited time (default is one week)
    - Once the data is written to a partition, it can't be changed (immutability)
  - Brokers
    - A kafka cluster is composed of multiple brokers (servers)
    - Each broker is identified with its ID (integer)
    - Each broker contains certain topic partitions
    - After connecting to any broker, you will be connected to the entire cluster
  - Topic replication factor
    - topics should have a replication factor > 1
    - if a broker is down, another broker can serve the data
    - At any time, only one broker can be a leader for a given partition. Only that leader can receive and serve data for a partition. The other brokers will synchronize the data. Therefore each partition has one leader and multiple ISR (in-sync replica)
  - Producers
    - Producers write data to topics
    - Producers automatically know to which broker and partition to write to
    - In case of broker failures, producers will automatically recover
    - Producers can choose to receive acknowledgement of data writes:
      - acks=0: producer won't wait for acknowledgement
      - acks=1: producer will wait for leader acknowledgement
      - acks=all: leader + replicas acknowledgement
    - message keys:
      - producers can choose to send a key with the message
      - if key=null, data is sent round robin
      - if a key is sent, then all messages for that key will always go to the same partition
  - Consumers
    - Consumers read data from a topic
    - consumers know which broker to read from
    - In case of broker failures, consumers know how to recover
    - Data is read in order **within each partitions**, but no specific order across partitions
    - Consumer groups:
      - consumers read data in consumer groups
      - each consumer within a group reads from exclusive partitions
      - if you have more consumers than partitions, some consumers will be inactive
  - Consumer offsets
    - kafka stores the offsets at which a consumer group has been reading (like a checkpoint)
    - the offsets committed live in a kafka topic named __consumer_offsets
    - when a consumer in a group has processed data received from kafka, it should committing the offsets
    - if a consumer dies, it will be able to read back from where it left off based on the offsets
    - consumers choose when to commit offsets
    - 3 delivery semantics:
      - At most once: offsets are commited as soon as the message is received; if the processing goes wrong, the message will be lost
      - At least once (preferred): offsets are commited after the message is processed. If the processing goes wrong, the message will be read again. This could result in duplicate processing of messages. Make sure the processing is idempotent (ie.e. processing again the messages won't impact your system
      - Exactly once: can only be achieved for kafka => kafka workflows using afka streams API
  - Kafka Broker Discovery
    - Every kafka broker is also called "bootstrap server" which means you only need to connct to one broker and you will be connected to the entire cluster
    - Each broker knows about all brokers, topics and partitions (metadata)
    - kafka client sends connection + metadata request, broker gives back list of all brokers, client can connect to the needed brokers
  - Zookeeper
    - it manages brokers (keeps a list of them) (connects to kafka broker)
    - it helps in performing leader election for partitions
    - it sends notifications to kafka in case of changes (e.g. new topic, broker dies etc)
    - kafka can't work without zookeeper
    - zookeeper by design operates with an odd number of servers
    - zookeeper has a leader (handle writes), the rest of the servers are followers (handle reads)
    - zookeeper does not store consumer offsets with kafka
    
